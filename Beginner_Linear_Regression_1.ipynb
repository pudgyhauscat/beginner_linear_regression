{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjI77N9i6C+Va93Mytly14",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pudgyhauscat/beginner_linear_regression/blob/main/Beginner_Linear_Regression_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "IOgANF6apguo"
      },
      "outputs": [],
      "source": [
        "#below is code for a linear regression on a generated data set with an equation \n",
        "#of y = 2 + 3*x_1 + x_2 - 6*x_3 and y = 2 + 3*x_1 + x_2 - 6*x_3 + u. \n",
        "\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "#initialize three independent variables. each variable has 50 observations with \n",
        "#their lowest value possible at 1 and highest possible value at 50. all of this \n",
        "#info can be customized. \n",
        "\n",
        "x_1 = np.random.randint(low = 1, high = 20, size = 100)\n",
        "x_2 = np.random.randint(low = 1, high = 20, size = 100)\n",
        "x_3 = np.random.randint(low = 1, high = 20, size = 100)\n",
        "\n",
        "#calculate the dependent variable based on the independent variable and the \n",
        "#intercept. we're using the variable i to stand for an index so that the list \n",
        "#comprehension can effectively move through two lists of the same size at the \n",
        "#same time.\n",
        "\n",
        "linear_y = [3*x for x in x_1]\n",
        "linear_y_2 = [linear_y[i] + x_2[i] for i in range(0,len(x_2))]\n",
        "linear_y_3 = [linear_y_2[i] - 6*x_3[i] for i in range(0, len(x_3))]\n",
        "linear_y_3 = np.array(linear_y_3) + 2\n",
        "\n",
        "#we have the option to add noise to the model. here we opt to add normally \n",
        "#distributed noise, which is a standard assumption of the model. later we'll use \n",
        "#the dependent variable with noise and a dependent variable without noise. to \n",
        "#compare outcomes\n",
        "\n",
        "noise = np.random.normal(10, 3, 100)\n",
        "linear_y_3_with_noise = [linear_y_3[i] + noise[i] for i in range(0, len(noise))]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here we'll create a matrix using our previously declared independent variables \n",
        "#called X_0. Linear regression is an equation of the form Ax = b, so this step \n",
        "#creates A. Designated capital X_0. we have b we want x. training the model is \n",
        "#simple once the data is set. Worth noting is that sk_learn's regression model \n",
        "#is going to use a single value decomposition, which is computationally \n",
        "#different than other methods we might use. \n",
        "\n",
        "X_0 = np.column_stack([x_1, x_2, x_3])\n",
        "sk_learn_regression_noiseless = LinearRegression()\n",
        "sk_learn_regression_noiseless.fit(X_0, linear_y_3)\n",
        "sk_learn_regression_noiseless.intercept_, sk_learn_regression_noiseless.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrc5XM4A4kOX",
        "outputId": "be380e1c-c45f-41dc-c296-a4ca5e68e86b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.0000000000000053, array([ 3.,  1., -6.]))"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here the same X_0 from above is used. we substitute linear_y_3 with \n",
        "#linear_y_3_with_noise. it changes the outcomes of the regression. we will \n",
        "#struggle to get the actual parameters because of the error we've introduced. \n",
        "\n",
        "sk_learn_regression_with_noise = LinearRegression()\n",
        "sk_learn_regression_with_noise.fit(X_0, linear_y_3_with_noise)\n",
        "sk_learn_regression_with_noise.intercept_, sk_learn_regression_with_noise.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v6-4xE7ANr3",
        "outputId": "4e48dfc7-7fae-4738-f885-dbcf2a47f53a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12.795712531253463, array([ 2.93760573,  0.9112158 , -5.89383994]))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generally we'd split the data into a train and test set. here we split the observations\n",
        "#and the noiseless data. we train the model with a simple call to LinearRegression() from\n",
        "#sklearn. then we just use the .split method and specific our dependent and independent variables\n",
        "\n",
        "x_test_noiseless, x_train_noiseless, y_test_noiseless, y_train_noiseless = train_test_split(X_0, linear_y_3, test_size = .2)\n",
        "\n",
        "sk_learn_regression_with_split_noiseless= LinearRegression()\n",
        "sk_learn_regression_with_split_noiseless.fit(x_train_noiseless, y_train_noiseless)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcQXayyrAEeP",
        "outputId": "cde4ec49-d519-45ab-b678-905013d3f695"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we see that in the noisless model the coefficients are found on the training set\n",
        "\n",
        "sk_learn_regression_with_split_noiseless.intercept_, sk_learn_regression_with_split_noiseless.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6CGC7iNhG-Z",
        "outputId": "ffda51d9-ba0f-4617-91bf-92ff79f5f333"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.0000000000000284, array([ 3.,  1., -6.]))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we use the model built on the trian set to make predictions on the test set. \n",
        "#we use the standard mean squared error for linear regression and get a very small error\n",
        "\n",
        "predictions_with_split_noiseless = sk_learn_regression_with_split_noiseless.predict(x_test_noiseless)\n",
        "\n",
        "metrics.mean_squared_error(predictions_with_split_noiseless, y_test_noiseless)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbcpkZtC-jT_",
        "outputId": "3372ef7c-f1f6-4d8a-a1ad-d0f335d5a352"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.1743762826093513e-28"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here is a split for a regression with noise and the model training process \n",
        "\n",
        "x_test_noise, x_train_noise, y_test_noise, y_train_noise = train_test_split(X_0, linear_y_3_with_noise, test_size = .2)\n",
        "\n",
        "sk_learn_regression_with_split_noise= LinearRegression()\n",
        "sk_learn_regression_with_split_noise.fit(x_train_noise, y_train_noise)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noDhATW-EYzW",
        "outputId": "83154194-685a-47b0-d704-063c36b3b3a1"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we see that in the noisless model the coefficients are not found exactly on the training\n",
        "#set with noise\n",
        "\n",
        "sk_learn_regression_with_split_noise.intercept_, sk_learn_regression_with_split_noise.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-WoaoWVK8LB",
        "outputId": "7570eba3-9785-4d05-9c2b-2cfbcf1e21bc"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14.843149097448055, array([ 2.82993006,  0.86623827, -5.96842683]))"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#since we didn't find the exact parameters we're left with less accurate predictions.\n",
        "#this is much more likely than the above outcome. train_test_split won't always split \n",
        "#the data in the same way based on how we configured it above. so, the model will have varying\n",
        "#coefficients and varying errors. in practice we'd want to find the best model that doesn't\n",
        "#overfit or underfit\n",
        "\n",
        "predictions_with_split_noise = sk_learn_regression_with_split_noise.predict(x_test_noise)\n",
        "\n",
        "metrics.mean_squared_error(predictions_with_split_noise, y_test_noise)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTRyyfhZQjDH",
        "outputId": "fd068e43-eee0-493b-e96f-a9a1e64766fc"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.88526494699631"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the data generation step included above can be fit into a class and ported out of this program\n",
        "#this will be useful, because we're going to use the same data generation steps in later notebooks. \n",
        "#this class will initialize data sets in the exact same way that we initialized the data set here and \n",
        "#we won't waste time coding it later\n",
        "\n",
        "class data_set_generator:\n",
        "  def __init__(self):\n",
        "    self.intercept = np.random.randint(low = 1, high = 20, size = 1)\n",
        "    self.x_1 = np.random.randint(low = 1, high = 20, size = 100)\n",
        "    self.x_2 = np.random.randint(low = 1, high = 20, size = 100)\n",
        "    self.x_3 = np.random.randint(low = 1, high = 20, size = 100)\n",
        "    self.X_0 = np.column_stack([self.x_1, self.x_2, self.x_3])\n",
        "    self.y = self.x_1"
      ],
      "metadata": {
        "id": "QwWpnVVG1dhm"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}